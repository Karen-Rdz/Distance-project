{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io\n",
    "from sklearn import svm\n",
    "\n",
    "#visual your data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16435401e-01 -1.08077103e-01 -7.96778474e-04 ...  2.41995733e-01\n",
      "   1.06491996e+00 -1.65087150e+01]\n",
      " [ 8.21688818e-02  9.03154376e-02 -6.85819650e-02 ...  2.41110796e-01\n",
      "   1.06419912e+00 -1.69006336e+01]\n",
      " [ 1.33964552e-01  3.67458529e-02  1.24008526e-01 ...  2.47017470e-01\n",
      "   1.03231275e+00 -2.79617826e+01]\n",
      " ...\n",
      " [-1.54932255e-03 -9.86014464e-02  6.91419771e-02 ... -3.90329885e-02\n",
      "   1.05517372e+00 -4.61726713e+00]\n",
      " [ 1.66201959e-01  1.95997625e-02  8.57325449e-03 ... -1.72576560e-02\n",
      "   1.03076338e+00 -5.24105714e+00]\n",
      " [ 4.92604832e-02 -8.13697169e-02 -5.27883007e-02 ... -3.17909040e-02\n",
      "   1.04372491e+00 -4.80904507e+00]]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "data_complete = scipy.io.loadmat('FeatureMatrices.mat')\n",
    "labels = data_complete['FMinfo']\n",
    "test = data_complete['WFM_1']\n",
    "clas = test[:, 129]\n",
    "\n",
    "x = np.delete(test, 129, axis=1)\n",
    "y = clas\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "Best Accuracy:  82.02\n",
      "Best Kernel:  RBF\n",
      "Number of features:  4\n",
      "{1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
      "Best Accuracy:  81.14\n",
      "Best Kernel:  RBF\n",
      "Number of features:  4\n",
      "{1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 1}\n",
      "Best Accuracy:  81.58\n",
      "Best Kernel:  RBF\n",
      "Number of features:  10\n",
      "{1: 0, 2: 1, 3: 0, 4: 2, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 1}\n",
      "Best Accuracy:  82.02\n",
      "Best Kernel:  RBF\n",
      "Number of features:  2\n",
      "{1: 0, 2: 1, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 0, 10: 1}\n",
      "Best Accuracy:  82.89\n",
      "Best Kernel:  RBF\n",
      "Number of features:  6\n",
      "{1: 1, 2: 1, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 0, 10: 1}\n",
      "Best Accuracy:  79.82\n",
      "Best Kernel:  RBF\n",
      "Number of features:  1\n",
      "{1: 1, 2: 2, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 0, 10: 1}\n",
      "Best Accuracy:  82.89\n",
      "Best Kernel:  RBF\n",
      "Number of features:  2\n",
      "{1: 1, 2: 2, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 0, 10: 2}\n",
      "Best Accuracy:  82.89\n",
      "Best Kernel:  RBF\n",
      "Number of features:  10\n",
      "{1: 1, 2: 3, 3: 0, 4: 2, 5: 0, 6: 1, 7: 0, 8: 0, 9: 0, 10: 2}\n",
      "Best Accuracy:  81.14\n",
      "Best Kernel:  RBF\n",
      "Number of features:  2\n",
      "{1: 1, 2: 3, 3: 0, 4: 2, 5: 1, 6: 1, 7: 0, 8: 0, 9: 0, 10: 2}\n",
      "Best Accuracy:  83.33\n",
      "Best Kernel:  RBF\n",
      "Number of features:  5\n",
      "----- Final results -----\n",
      "{1: 1, 2: 3, 3: 0, 4: 2, 5: 1, 6: 1, 7: 0, 8: 0, 9: 0, 10: 2}\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "num_features = 10\n",
    "dict_features = {}\n",
    "times = 10\n",
    "\n",
    "# Create dictionary\n",
    "for i in range (1, num_features+1):\n",
    "    dict_features[i] = 0\n",
    "\n",
    "# Calculating the best model 10 times\n",
    "for j in range (1, times+1):\n",
    "    best_accuracy = 0\n",
    "    best_kernel = ''\n",
    "    best_features = 0\n",
    "    for i in range(1, num_features+1):\n",
    "        # Las k mejores características\n",
    "        X_new = SelectKBest(chi2, k=num_features).fit_transform(abs(x), y)\n",
    "\n",
    "        # Split the data for train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3) \n",
    "        #print(X_train)\n",
    "\n",
    "        # RBF, Polynomial and Linear Kernel\n",
    "        rbf = svm.SVC(kernel='rbf', gamma=0.6, C=1).fit(X_train, y_train)\n",
    "        poly = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "        linear = svm.SVC(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "#         poly_pred_test = poly.predict(X_test)\n",
    "#         rbf_pred_test = rbf.predict(X_test)\n",
    "#         linear_pred_test = linear.predict(X_test)\n",
    "\n",
    "        poly_pred_test = cross_val_predict(poly, X_test, y_test, cv = 5)\n",
    "        rbf_pred_test = cross_val_predict(rbf, X_test, y_test, cv = 5)\n",
    "        linear_pred_test = cross_val_predict(linear, X_test, y_test, cv = 5)\n",
    "        #print(linear_pred_test)\n",
    "\n",
    "        # Accuracy test\n",
    "        poly_accuracy = accuracy_score(y_test, poly_pred_test)\n",
    "        poly_f1 = f1_score(y_test, poly_pred_test, average='weighted')\n",
    "\n",
    "        rbf_accuracy = accuracy_score(y_test, rbf_pred_test)\n",
    "        rbf_f1 = f1_score(y_test, rbf_pred_test, average='weighted')\n",
    "\n",
    "        linear_accuracy = accuracy_score(y_test, linear_pred_test)\n",
    "        linear_f1 = f1_score(y_test, linear_pred_test, average='weighted')\n",
    "\n",
    "        if poly_accuracy > rbf_accuracy and poly_accuracy > linear_accuracy and poly_accuracy > best_accuracy:\n",
    "            best_accuracy = poly_accuracy\n",
    "            best_kernel = 'Poly'\n",
    "            best_features = i\n",
    "        elif rbf_accuracy > poly_accuracy and rbf_accuracy > linear_accuracy and rbf_accuracy > best_accuracy:\n",
    "            best_accuracy = rbf_accuracy\n",
    "            best_kernel = 'RBF'\n",
    "            best_features = i\n",
    "        elif linear_accuracy > poly_accuracy and linear_accuracy > rbf_accuracy and linear_accuracy > best_accuracy:\n",
    "            best_accuracy = linear_accuracy\n",
    "            best_kernel = 'Linear'\n",
    "            best_features = i\n",
    "    dict_features[best_features] = dict_features[best_features] + 1\n",
    "    print(dict_features)\n",
    "        \n",
    "    print('Best Accuracy: ', \"%.2f\" % (best_accuracy*100))\n",
    "    print('Best Kernel: ', best_kernel)\n",
    "    print('Number of features: ', best_features)\n",
    "print('----- Final results -----')\n",
    "print(dict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.02486463e-01 2.54274970e-01 2.32483726e-01 ... 5.35495340e-02\n",
      "  1.03899548e+00 3.89400325e+00]\n",
      " [1.09183171e+00 1.22429057e+00 1.45242849e+00 ... 7.02608291e-01\n",
      "  1.13383250e+00 9.98963754e+00]\n",
      " [6.52342141e-02 1.75066378e-02 1.94286851e-02 ... 1.00987616e-01\n",
      "  1.10628601e+00 1.88318980e+01]\n",
      " ...\n",
      " [7.54837281e-02 9.42670386e-02 3.74402538e-02 ... 4.27003335e-02\n",
      "  1.09163226e+00 6.08398634e+00]\n",
      " [2.16719276e-02 3.84664378e-02 3.53518681e-02 ... 4.83768706e-02\n",
      "  1.18592487e+00 5.12516779e+00]\n",
      " [1.10729672e-01 1.55616327e-01 7.69010666e-02 ... 8.49812801e-02\n",
      "  1.19725471e+00 2.93480021e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Las k mejores características\n",
    "X_new = SelectKBest(chi2, k=8).fit_transform(abs(x), y)\n",
    "\n",
    "# Split the data for train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3) \n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF, Polynomial and Linear Kernel\n",
    "rbf = svm.SVC(kernel='rbf', gamma=0.6, C=1).fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)\n",
    "linear = svm.SVC(kernel='linear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 3. 2. 3. 2. 2.\n",
      " 3. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 3. 2. 2.\n",
      " 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2.\n",
      " 3. 2. 2. 2. 3. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 3. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 3. 2. 2. 2. 2. 2. 3. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 3. 2. 2. 3. 2. 2. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Predict values\n",
    "# poly_pred_test = poly.predict(X_test)\n",
    "# rbf_pred_test = rbf.predict(X_test)\n",
    "# linear_pred_test = linear.predict(X_test)\n",
    "\n",
    "# poly_pred_train = poly.predict(X_train)\n",
    "# rbf_pred_train = rbf.predict(X_train)\n",
    "# linear_pred_train = linear.predict(X_train)\n",
    "\n",
    "poly_pred_test = cross_val_predict(poly, X_test, y_test, cv = 5)\n",
    "rbf_pred_test = cross_val_predict(rbf, X_test, y_test, cv = 5)\n",
    "linear_pred_test = cross_val_predict(linear, X_test, y_test, cv = 5)\n",
    "\n",
    "poly_pred_train = cross_val_predict(poly, X_train, y_train, cv = 5)\n",
    "rbf_pred_train = cross_val_predict(rbf, X_train, y_train, cv = 5)\n",
    "linear_pred_train = cross_val_predict(linear, X_train, y_train, cv = 5)\n",
    "\n",
    "print(linear_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Accuracy Test-----\n",
      "Accuracy (Polynomial Kernel):  60.53\n",
      "F1 (Polynomial Kernel):  45.64 \n",
      "\n",
      "Accuracy (RBF Kernel):  75.88\n",
      "F1 (RBF Kernel):  70.81 \n",
      "\n",
      "Accuracy (Linear Kernel):  71.93\n",
      "F1 (Linear Kernel):  65.42 \n",
      "\n",
      "-----Accuracy Train-----\n",
      "Accuracy (Polynomial Kernel):  65.16\n",
      "F1 (Polynomial Kernel):  51.61 \n",
      "\n",
      "Accuracy (RBF Kernel):  79.66\n",
      "F1 (RBF Kernel):  75.49 \n",
      "\n",
      "Accuracy (Linear Kernel):  75.52\n",
      "F1 (Linear Kernel):  69.80\n"
     ]
    }
   ],
   "source": [
    "# Accuracy test\n",
    "print(\"-----Accuracy Test-----\")\n",
    "poly_accuracy = accuracy_score(y_test, poly_pred_test)\n",
    "poly_f1 = f1_score(y_test, poly_pred_test, average='weighted')\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100), '\\n')\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_test, rbf_pred_test)\n",
    "rbf_f1 = f1_score(y_test, rbf_pred_test, average='weighted')\n",
    "print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100), '\\n')\n",
    "\n",
    "linear_accuracy = accuracy_score(y_test, linear_pred_test)\n",
    "linear_f1 = f1_score(y_test, linear_pred_test, average='weighted')\n",
    "print('Accuracy (Linear Kernel): ', \"%.2f\" % (linear_accuracy*100))\n",
    "print('F1 (Linear Kernel): ', \"%.2f\" % (linear_f1*100), '\\n')\n",
    "\n",
    "# Accuracy train\n",
    "print(\"-----Accuracy Train-----\")\n",
    "poly_accuracy = accuracy_score(y_train, poly_pred_train)\n",
    "poly_f1 = f1_score(y_train, poly_pred_train, average='weighted')\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100), '\\n')\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_train, rbf_pred_train)\n",
    "rbf_f1 = f1_score(y_train, rbf_pred_train, average='weighted')\n",
    "print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100), '\\n')\n",
    "\n",
    "linear_accuracy = accuracy_score(y_train, linear_pred_train)\n",
    "linear_f1 = f1_score(y_train, linear_pred_train, average='weighted')\n",
    "print('Accuracy (Linear Kernel): ', \"%.2f\" % (linear_accuracy*100))\n",
    "print('F1 (Linear Kernel): ', \"%.2f\" % (linear_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the separating hyperplane\n",
    "w = linear.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(30, 60)\n",
    "yy = a * xx - (linear.intercept_[0]) / w[1]\n",
    "\n",
    "# plot the parallels to the separating hyperplane that pass through the support vectors\n",
    "b = linear.support_vectors_[0]\n",
    "yy_down = a * xx + (b[1] - a * b[0])\n",
    "b = linear.support_vectors_[-1]\n",
    "yy_up = a * xx + (b[1] - a * b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ecc433f70538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Features'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Clas'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Clas'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Set1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy_down\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy_up\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\u001b[0m in \u001b[0;36mlmplot\u001b[1;34m(x, y, data, hue, col, row, palette, col_wrap, height, aspect, markers, sharex, sharey, hue_order, col_order, row_order, legend, legend_out, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, x_jitter, y_jitter, scatter_kws, line_kws, size)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0mneed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_partial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_partial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mneed_cols\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;31m# Initialize the grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# plot data\n",
    "sns.lmplot('Features', 'Clas', data=test, hue='Clas', palette='Set1', fit_reg=False, scatter_kws={\"s\": 70});\n",
    "plt.plot(xx, yy, linewidth=2, color='black')\n",
    "plt.plot(xx, yy_down, 'k--')\n",
    "plt.plot(xx, yy_up, 'k--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
